# The-starting-of-NLP

# 首先用google的文档来做一个简单的NLP介绍

This repository is the translation of [google text classification tutorial](https://developers.google.com/machine-learning/guides/text-classification/)

> 如果要转载或者复制粘贴请标明原作者谢谢!

## 目录结构

* [一、简介(Introduction)](Doc/Introduction.md)

* [二、收集数据(Step 1: Gather Data)](Doc/Gather_Data.md)

* [三、数据探索(Step 2:Explore_Your_Data)](/Doc/Explore_Your_Data.md)

* [四、选择模型(Step 2.5: Choose a Model)](/Doc/Choose_a_Model.md)

* [五、数据准备(Step 3: Prepare_Your_Data)](/Doc/Prepare_Your_Data.md)

* [六、构建，培训和评估您的模型(Step 4: Build_Train_and_Evaluate_Your_Model)](/Doc/Build_Train_and_Evaluate_Your_Model.md)

* [七、调整超参数(Step 5: Tune_Hyperparameters)](/Doc/Tune_Hyperparameters.md)

* [八、部署模型(Step 6: Deploy_Your_Model)](/Doc/Deploy_Your_Model.md)

* [九、总结(Step 7: Conclusion)](/Doc/Conclusion.md)

* [十、附录：批量训练(Step 8: Appendix:Batch_Training)](/Doc/Appendix:Batch_Training.md)
----------------------------------------------------------------------------------------------------------------------------------

# 深度学习模型

>这里用keras还有TensorFlow实现了一些深度学习的模型(大部分采用GPU并行计算)

## (1)文本分类
* [1.Text cnn](/deep_learning_model/TEXTCNN)
* [2.Bi-gru attention](/deep_learning_model/BIGRU_ATTENTION)
* [3.Fast text](/deep_learning_model/FASTTEXT/)
* [4.Bi-gru fasttext](/deep_learning_model/BIGRU_FASTTEXT/)
* [5.Res net](deep_learning_model/RESNET/)
* [6.cnn attention](deep_learning_model/CNN_ATTENTION)
# 相关论文与笔记
* [1.Word2Vec](/Doc/Word2Vec/Word2vec原理.docx)
* [2.LDA](/Doc/LDA/LDA主题模型.docx)
* [3.ResNet](/Doc/ResNet/resnet笔记.docx)
* [4.Fasttext](/Doc/Fasttext/fasttext笔记.docx)
* [5.Seq-to-Seq](/Doc/Seq_to_Seq/Seq-to-Seq-notes.pdf)
* [6.Attention](/Doc/Attention/attention-z.docx)
* [7.Bi-LSTM-Attention](/Doc/Bi-LSTM-Attention/Bi-LSTM-Attention.pdf)
* [8.ELMo](/Doc/ELMo/ELMo_notes.pdf)
* [9.BERT](/Doc/BERT/BERT-notes.docx)
